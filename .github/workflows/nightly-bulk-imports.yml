name: Nightly Bulk Data Import

on:
  # Run every night at 2:00 AM UTC
  schedule:
    - cron: '0 2 * * *'
  
  # Allow manual triggering for testing
  workflow_dispatch:
    inputs:
      debug_mode:
        description: 'Enable extra debug logging'
        required: false
        default: 'true'
        type: boolean

jobs:
  bulk-import:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Generous timeout to prevent crashes
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up environment
        run: |
          echo "ğŸš€ Starting nightly bulk data import"
          echo "ğŸ“… Run date: $(date -u)"
          echo "ğŸ”§ GitHub Actions Runner: ubuntu-latest"
          echo "â° Timeout: 60 minutes"
      
      - name: Health Check - Ping Vercel Application
        id: health_check
        run: |
          echo "ğŸ¥ Checking if Vercel application is reachable..."
          HEALTH_URL="${{ secrets.VERCEL_URL }}/api/health"
          
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$HEALTH_URL" || echo "000")
          
          if [ "$HTTP_CODE" = "200" ]; then
            echo "âœ… Vercel is healthy (HTTP $HTTP_CODE)"
          else
            echo "âš ï¸ Vercel returned HTTP $HTTP_CODE"
            echo "âš ï¸ Continuing anyway"
          fi
          
          echo "health_status=$HTTP_CODE" >> $GITHUB_OUTPUT
      
      - name: Wake Up Render Service (FREE tier spindown handling)
        id: render_wakeup
        run: |
          echo "ğŸŒ… Waking up Render FREE tier service..."
          echo "ğŸ’¤ Render spins down after 15min inactivity"
          echo "â° Cold start takes ~60-90 seconds"
          
          RENDER_HEALTH="https://mtg-bulk-jobs.onrender.com/health"
          
          echo "ğŸ”” Pinging Render health endpoint (2 min timeout)..."
          START=$(date +%s)
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 120 "$RENDER_HEALTH" || echo "000")
          END=$(date +%s)
          DURATION=$((END - START))
          
          echo "ğŸ“¡ Response: HTTP $HTTP_CODE in ${DURATION}s"
          
          if [ "$HTTP_CODE" = "200" ]; then
            echo "âœ… Render is awake!"
            if [ $DURATION -gt 10 ]; then
              echo "â° Service was cold, took ${DURATION}s to wake up"
              echo "â³ Waiting 20 more seconds for full initialization..."
              sleep 20
            else
              echo "ğŸš€ Service was already warm!"
            fi
          else
            echo "âŒ Render health check failed (HTTP $HTTP_CODE)"
            echo "â³ Waiting 60s and retrying..."
            sleep 60
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 120 "$RENDER_HEALTH" || echo "000")
            if [ "$HTTP_CODE" = "200" ]; then
              echo "âœ… Render is awake after retry!"
              echo "â³ Waiting 20s for full initialization..."
              sleep 20
            else
              echo "âŒ Render still not responding, jobs will likely fail"
              exit 1
            fi
          fi
      
      # Job 1 - DISABLED: Run locally due to Render FREE tier 512MB RAM limit
      # Bulk Scryfall import requires ~100MB+ JSON file which exceeds free tier
      # To run manually: cd bulk-jobs-server && npm start, then POST to localhost:3001/bulk-scryfall
      
      # - name: Job 1 - Bulk Scryfall Import (Metadata)
      #   id: job1
      #   continue-on-error: false
      #   run: |
      #     echo "ğŸ¨ =========================================="
      #     echo "ğŸ¨ JOB 1: Bulk Scryfall Import (Metadata)"
      #     echo "ğŸ¨ =========================================="
      #     echo "ğŸ“‹ What: Downloads ALL 110k+ cards with metadata"
      #     echo "ğŸ’¾ Target: scryfall_cache table"
      #     echo "â±ï¸ Expected: 3-5 minutes"
      #     echo ""
      #     
      #     START_TIME=$(date +%s)
      #     echo "ğŸ• Start time: $(date -u)"
      #     
      #     API_URL="https://mtg-bulk-jobs.onrender.com/bulk-scryfall"
      #     echo "ğŸŒ Calling: $API_URL"
      #     
      #     # Make the request with detailed output
      #     HTTP_CODE=$(curl -X POST \
      #       -H "x-cron-key: ${{ secrets.CRON_KEY }}" \
      #       -H "Content-Type: application/json" \
      #       -H "User-Agent: GitHub-Actions-Nightly-Import/1.0" \
      #       -w "\n%{http_code}" \
      #       -s \
      #       --max-time 600 \
      #       --connect-timeout 30 \
      #       "$API_URL" \
      #       -o response.json)
      #     
      #     END_TIME=$(date +%s)
      #     DURATION=$((END_TIME - START_TIME))
      #     
      #     echo ""
      #     echo "â±ï¸ Completed in: ${DURATION} seconds"
      #     echo "ğŸ“¡ HTTP Status: $HTTP_CODE"
      #     echo ""
      #     echo "ğŸ“„ Response body:"
      #     cat response.json | jq '.' || cat response.json
      #     echo ""
      #     
      #     # Check for success
      #     if [ "$HTTP_CODE" = "200" ]; then
      #       echo "âœ… Job 1 completed successfully!"
      #       
      #       # Extract stats if available
      #       INSERTED=$(cat response.json | jq -r '.inserted // "N/A"')
      #       PROCESSED=$(cat response.json | jq -r '.processed // "N/A"')
      #       echo "ğŸ“Š Stats: Processed=$PROCESSED, Inserted=$INSERTED"
      #     else
      #       echo "âŒ Job 1 failed with HTTP $HTTP_CODE"
      #       echo "ğŸ” Error details:"
      #       cat response.json | jq -r '.error // "No error message"' || echo "Could not parse error"
      #       exit 1
      #     fi
      #     
      #     echo "job1_duration=$DURATION" >> $GITHUB_OUTPUT
      #     echo "job1_status=success" >> $GITHUB_OUTPUT
      
      # Wait removed - Job 1 disabled
      
      - name: Job 2 - Bulk Price Import (Live Prices)
        id: job2
        continue-on-error: false
        run: |
          echo "ğŸ’° =========================================="
          echo "ğŸ’° JOB 2: Bulk Price Import (Live Prices)"
          echo "ğŸ’° =========================================="
          echo "ğŸ“‹ What: Updates prices for ALL cached cards"
          echo "ğŸ’¾ Target: scryfall_cache table (price fields)"
          echo "â±ï¸ Expected: 3-5 minutes"
          echo ""
          
          START_TIME=$(date +%s)
          echo "ğŸ• Start time: $(date -u)"
          
          API_URL="https://mtg-bulk-jobs.onrender.com/bulk-price-import"
          echo "ğŸŒ Calling: $API_URL"
          
          HTTP_CODE=$(curl -X POST \
            -H "x-cron-key: ${{ secrets.CRON_KEY }}" \
            -H "Content-Type: application/json" \
            -H "User-Agent: GitHub-Actions-Nightly-Import/1.0" \
            -w "%{http_code}" \
            -s \
            --max-time 600 \
            --connect-timeout 30 \
            "$API_URL" \
            -o response.json)
          
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo ""
          echo "â±ï¸ Completed in: ${DURATION} seconds"
          echo "ğŸ“¡ HTTP Status: $HTTP_CODE"
          echo ""
          echo "ğŸ“„ Response body:"
          cat response.json | jq '.' || cat response.json
          echo ""
          
          if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "202" ]; then
            echo "âœ… Job 2 completed successfully! (HTTP $HTTP_CODE)"
            
            if [ "$HTTP_CODE" = "202" ]; then
              echo "â„¹ï¸ Job accepted and running in background (3-5 minutes)"
            fi
            
            UPDATED=$(cat response.json | jq -r '.updated // "N/A"')
            COVERAGE=$(cat response.json | jq -r '.coverage // "N/A"')
            echo "ğŸ“Š Stats: Updated=$UPDATED, Coverage=$COVERAGE"
          else
            echo "âŒ Job 2 failed with HTTP $HTTP_CODE"
            echo "ğŸ” Error details:"
            cat response.json | jq -r '.error // "No error message"' || echo "Could not parse error"
            exit 1
          fi
          
          echo "job2_duration=$DURATION" >> $GITHUB_OUTPUT
          echo "job2_status=success" >> $GITHUB_OUTPUT
      
      - name: Wait between jobs (5 seconds)
        run: |
          echo "â¸ï¸ Waiting 5 seconds before next job..."
          sleep 5
      
      - name: Job 3 - Historical Price Snapshots
        id: job3
        continue-on-error: false
        run: |
          echo "ğŸ“ˆ =========================================="
          echo "ğŸ“ˆ JOB 3: Historical Price Snapshots"
          echo "ğŸ“ˆ =========================================="
          echo "ğŸ“‹ What: Creates historical price snapshots"
          echo "ğŸ’¾ Target: price_snapshots table"
          echo "â±ï¸ Expected: 2-3 minutes"
          echo ""
          
          START_TIME=$(date +%s)
          echo "ğŸ• Start time: $(date -u)"
          
          API_URL="https://mtg-bulk-jobs.onrender.com/price-snapshot"
          echo "ğŸŒ Calling: $API_URL"
          
          HTTP_CODE=$(curl -X POST \
            -H "x-cron-key: ${{ secrets.CRON_KEY }}" \
            -H "Content-Type: application/json" \
            -H "User-Agent: GitHub-Actions-Nightly-Import/1.0" \
            -w "%{http_code}" \
            -s \
            --max-time 600 \
            --connect-timeout 30 \
            "$API_URL" \
            -o response.json)
          
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo ""
          echo "â±ï¸ Completed in: ${DURATION} seconds"
          echo "ğŸ“¡ HTTP Status: $HTTP_CODE"
          echo ""
          echo "ğŸ“„ Response body:"
          cat response.json | jq '.' || cat response.json
          echo ""
          
          if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "202" ]; then
            echo "âœ… Job 3 completed successfully! (HTTP $HTTP_CODE)"
            
            if [ "$HTTP_CODE" = "202" ]; then
              echo "â„¹ï¸ Job accepted and running in background (2-3 minutes)"
            fi
            
            INSERTED=$(cat response.json | jq -r '.inserted // "N/A"')
            SNAPSHOT_DATE=$(cat response.json | jq -r '.snapshot_date // "N/A"')
            echo "ğŸ“Š Stats: Inserted=$INSERTED, Date=$SNAPSHOT_DATE"
          else
            echo "âŒ Job 3 failed with HTTP $HTTP_CODE"
            echo "ğŸ” Error details:"
            cat response.json | jq -r '.error // "No error message"' || echo "Could not parse error"
            exit 1
          fi
          
          echo "job3_duration=$DURATION" >> $GITHUB_OUTPUT
          echo "job3_status=success" >> $GITHUB_OUTPUT
      
      - name: Summary
        if: always()
        run: |
          echo ""
          echo "ğŸ‰ =========================================="
          echo "ğŸ‰ NIGHTLY IMPORT SUMMARY"
          echo "ğŸ‰ =========================================="
          echo ""
          echo "ğŸ“… Run completed: $(date -u)"
          echo ""
          echo "Job Results:"
          echo "  ğŸ¨ Job 1 (Metadata):  ${{ steps.job1.outputs.job1_status || 'FAILED' }} - ${{ steps.job1.outputs.job1_duration || 'N/A' }}s"
          echo "  ğŸ’° Job 2 (Prices):    ${{ steps.job2.outputs.job2_status || 'FAILED' }} - ${{ steps.job2.outputs.job2_duration || 'N/A' }}s"
          echo "  ğŸ“ˆ Job 3 (Snapshots): ${{ steps.job3.outputs.job3_status || 'FAILED' }} - ${{ steps.job3.outputs.job3_duration || 'N/A' }}s"
          echo ""
          
          TOTAL_TIME=$((
            ${{ steps.job1.outputs.job1_duration || 0 }} +
            ${{ steps.job2.outputs.job2_duration || 0 }} +
            ${{ steps.job3.outputs.job3_duration || 0 }}
          ))
          echo "â±ï¸ Total runtime: ${TOTAL_TIME} seconds (~$((TOTAL_TIME / 60)) minutes)"
          echo ""
          
          if [ "${{ job.status }}" = "success" ]; then
            echo "âœ… All jobs completed successfully!"
          else
            echo "âŒ Some jobs failed - check logs above"
          fi
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: failure-logs-${{ github.run_id }}
          path: |
            response.json
          retention-days: 7

