name: Nightly Bulk Data Import

on:
  # Run every night at 2:00 AM UTC
  schedule:
    - cron: '0 2 * * *'
  
  # Allow manual triggering for testing
  workflow_dispatch:
    inputs:
      debug_mode:
        description: 'Enable extra debug logging'
        required: false
        default: 'true'
        type: boolean

jobs:
  bulk-import:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Generous timeout to prevent crashes
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up environment
        run: |
          echo "üöÄ Starting nightly bulk data import"
          echo "üìÖ Run date: $(date -u)"
          echo "üîß GitHub Actions Runner: ubuntu-latest"
          echo "‚è∞ Timeout: 60 minutes"
      
      - name: Health Check - Ping Vercel Application
        id: health_check
        run: |
          echo "üè• Checking if Vercel application is reachable..."
          HEALTH_URL="${{ secrets.VERCEL_URL }}/api/health"
          
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$HEALTH_URL" || echo "000")
          
          if [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Vercel is healthy (HTTP $HTTP_CODE)"
          else
            echo "‚ö†Ô∏è Vercel returned HTTP $HTTP_CODE"
            echo "‚ö†Ô∏è Continuing anyway"
          fi
          
          echo "health_status=$HTTP_CODE" >> $GITHUB_OUTPUT
      
      - name: Wake Up Render Service (FREE tier spindown handling)
        id: render_wakeup
        run: |
          echo "üåÖ Waking up Render FREE tier service..."
          echo "üí§ Render spins down after 15min inactivity"
          echo "‚è∞ Cold start takes ~60-90 seconds"
          
          RENDER_HEALTH="https://mtg-bulk-jobs.onrender.com/health"
          
          echo "üîî Pinging Render health endpoint (2 min timeout)..."
          START=$(date +%s)
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 120 "$RENDER_HEALTH" || echo "000")
          END=$(date +%s)
          DURATION=$((END - START))
          
          echo "üì° Response: HTTP $HTTP_CODE in ${DURATION}s"
          
          if [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Render is awake!"
            if [ $DURATION -gt 10 ]; then
              echo "‚è∞ Service was cold, took ${DURATION}s to wake up"
              echo "‚è≥ Waiting 20 more seconds for full initialization..."
              sleep 20
            else
              echo "üöÄ Service was already warm!"
            fi
          else
            echo "‚ùå Render health check failed (HTTP $HTTP_CODE)"
            echo "‚è≥ Waiting 60s and retrying..."
            sleep 60
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 120 "$RENDER_HEALTH" || echo "000")
            if [ "$HTTP_CODE" = "200" ]; then
              echo "‚úÖ Render is awake after retry!"
              echo "‚è≥ Waiting 20s for full initialization..."
              sleep 20
            else
              echo "‚ùå Render still not responding, jobs will likely fail"
              exit 1
            fi
          fi
      
      # Job 1 - DISABLED: Run locally due to Render FREE tier 512MB RAM limit
      # Bulk Scryfall import requires ~100MB+ JSON file which exceeds free tier
      # To run manually: cd bulk-jobs-server && npm start, then POST to localhost:3001/bulk-scryfall
      
      # - name: Job 1 - Bulk Scryfall Import (Metadata)
      #   id: job1
      #   continue-on-error: false
      #   run: |
      #     echo "üé® =========================================="
      #     echo "üé® JOB 1: Bulk Scryfall Import (Metadata)"
      #     echo "üé® =========================================="
      #     echo "üìã What: Downloads ALL 110k+ cards with metadata"
      #     echo "üíæ Target: scryfall_cache table"
      #     echo "‚è±Ô∏è Expected: 3-5 minutes"
      #     echo ""
      #     
      #     START_TIME=$(date +%s)
      #     echo "üïê Start time: $(date -u)"
      #     
      #     API_URL="https://mtg-bulk-jobs.onrender.com/bulk-scryfall"
      #     echo "üåê Calling: $API_URL"
      #     
      #     # Make the request with detailed output
      #     HTTP_CODE=$(curl -X POST \
      #       -H "x-cron-key: ${{ secrets.CRON_KEY }}" \
      #       -H "Content-Type: application/json" \
      #       -H "User-Agent: GitHub-Actions-Nightly-Import/1.0" \
      #       -w "\n%{http_code}" \
      #       -s \
      #       --max-time 600 \
      #       --connect-timeout 30 \
      #       "$API_URL" \
      #       -o response.json)
      #     
      #     END_TIME=$(date +%s)
      #     DURATION=$((END_TIME - START_TIME))
      #     
      #     echo ""
      #     echo "‚è±Ô∏è Completed in: ${DURATION} seconds"
      #     echo "üì° HTTP Status: $HTTP_CODE"
      #     echo ""
      #     echo "üìÑ Response body:"
      #     cat response.json | jq '.' || cat response.json
      #     echo ""
      #     
      #     # Check for success
      #     if [ "$HTTP_CODE" = "200" ]; then
      #       echo "‚úÖ Job 1 completed successfully!"
      #       
      #       # Extract stats if available
      #       INSERTED=$(cat response.json | jq -r '.inserted // "N/A"')
      #       PROCESSED=$(cat response.json | jq -r '.processed // "N/A"')
      #       echo "üìä Stats: Processed=$PROCESSED, Inserted=$INSERTED"
      #     else
      #       echo "‚ùå Job 1 failed with HTTP $HTTP_CODE"
      #       echo "üîç Error details:"
      #       cat response.json | jq -r '.error // "No error message"' || echo "Could not parse error"
      #       exit 1
      #     fi
      #     
      #     echo "job1_duration=$DURATION" >> $GITHUB_OUTPUT
      #     echo "job1_status=success" >> $GITHUB_OUTPUT
      
      # Wait removed - Job 1 disabled
      
      - name: Job 2 - Bulk Price Import (Live Prices)
        id: job2
        continue-on-error: false
        run: |
          echo "üí∞ =========================================="
          echo "üí∞ JOB 2: Bulk Price Import (Live Prices)"
          echo "üí∞ =========================================="
          echo "üìã What: Updates prices for ALL cached cards"
          echo "üíæ Target: scryfall_cache table (price fields)"
          echo "‚è±Ô∏è Expected: 3-5 minutes"
          echo ""
          
          START_TIME=$(date +%s)
          echo "üïê Start time: $(date -u)"
          
          API_URL="https://mtg-bulk-jobs.onrender.com/bulk-price-import"
          echo "üåê Calling: $API_URL"
          
          HTTP_CODE=$(curl -X POST \
            -H "x-cron-key: ${{ secrets.CRON_KEY }}" \
            -H "Content-Type: application/json" \
            -H "User-Agent: GitHub-Actions-Nightly-Import/1.0" \
            -w "%{http_code}" \
            -s \
            --max-time 600 \
            --connect-timeout 30 \
            "$API_URL" \
            -o response.json)
          
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo ""
          echo "‚è±Ô∏è Completed in: ${DURATION} seconds"
          echo "üì° HTTP Status: $HTTP_CODE"
          echo ""
          echo "üìÑ Response body:"
          cat response.json | jq '.' || cat response.json
          echo ""
          
          if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "202" ]; then
            echo "‚úÖ Job 2 completed successfully! (HTTP $HTTP_CODE)"
            
            if [ "$HTTP_CODE" = "202" ]; then
              echo "‚ÑπÔ∏è Job accepted and running in background (3-5 minutes)"
            fi
            
            UPDATED=$(cat response.json | jq -r '.updated // "N/A"')
            COVERAGE=$(cat response.json | jq -r '.coverage // "N/A"')
            echo "üìä Stats: Updated=$UPDATED, Coverage=$COVERAGE"
          else
            echo "‚ùå Job 2 failed with HTTP $HTTP_CODE"
            echo "üîç Error details:"
            cat response.json | jq -r '.error // "No error message"' || echo "Could not parse error"
            exit 1
          fi
          
          echo "job2_duration=$DURATION" >> $GITHUB_OUTPUT
          echo "job2_status=success" >> $GITHUB_OUTPUT
      
      - name: Verify Job 2 Completion
        id: verify_job2
        continue-on-error: false
        run: |
          echo ""
          echo "üîç =========================================="
          echo "üîç VERIFYING JOB 2 COMPLETION"
          echo "üîç =========================================="
          echo ""
          echo "‚è≥ Waiting 6 minutes for background job to complete..."
          echo "‚è∞ Start wait: $(date -u)"
          sleep 360  # Wait 6 minutes for job to finish
          echo "‚è∞ End wait: $(date -u)"
          echo ""
          
          echo "üìä Checking database for completion..."
          
          # Query Supabase to check if job completed
          SUPABASE_URL="${{ secrets.SUPABASE_URL }}"
          SUPABASE_KEY="${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}"
          
          # Validate secrets are set
          if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_KEY" ]; then
            echo "‚ùå Missing Supabase secrets (SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY)"
            echo "verify_job2_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Get the timestamp before job started (approximately) - use minutes subtraction for UTC
          BEFORE_JOB=$(date -u -d '10 minutes ago' +"%Y-%m-%dT%H:%M:%S" 2>/dev/null || date -u -v-10M +"%Y-%m-%dT%H:%M:%S" 2>/dev/null || echo "")
          
          if [ -z "$BEFORE_JOB" ]; then
            # Fallback: calculate manually
            BEFORE_JOB=$(date -u +"%Y-%m-%dT%H:%M:%S")
            echo "‚ö†Ô∏è Could not calculate '10 minutes ago', using current time minus buffer"
          fi
          
          echo "üîç Querying: $SUPABASE_URL/rest/v1/app_config?key=eq.job:last:bulk_price_import&select=value"
          
          # Check app_config for last run timestamp
          RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" \
            -H "apikey: $SUPABASE_KEY" \
            -H "Authorization: Bearer $SUPABASE_KEY" \
            "$SUPABASE_URL/rest/v1/app_config?key=eq.job:last:bulk_price_import&select=value" || echo "")
          
          HTTP_CODE=$(echo "$RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2 || echo "000")
          RESPONSE_BODY=$(echo "$RESPONSE" | grep -v "HTTP_CODE:" || echo "")
          
          echo "üì° HTTP Status: $HTTP_CODE"
          echo "üìÑ Response: $RESPONSE_BODY"
          
          if [ "$HTTP_CODE" != "200" ]; then
            echo "‚ùå Supabase query failed with HTTP $HTTP_CODE"
            echo "verify_job2_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          LAST_RUN=$(echo "$RESPONSE_BODY" | jq -r '.[0].value // empty' 2>/dev/null || echo "")
          
          if [ -z "$LAST_RUN" ] || [ "$LAST_RUN" = "null" ]; then
            echo "‚ùå Could not find job:last:bulk_price_import in database"
            echo "‚ùå Response was: $RESPONSE_BODY"
            echo "verify_job2_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "üìÖ Last run timestamp: $LAST_RUN"
          echo "üìÖ Job started after: $BEFORE_JOB"
          
          # Check if timestamp is recent (within last 15 minutes to account for job duration)
          # Parse ISO timestamp (handle with or without timezone)
          LAST_RUN_CLEANED=$(echo "$LAST_RUN" | sed 's/\.[0-9]*//' | sed 's/Z$//')
          BEFORE_JOB_CLEANED=$(echo "$BEFORE_JOB" | sed 's/Z$//')
          
          LAST_RUN_EPOCH=$(date -u -d "$LAST_RUN_CLEANED" +%s 2>/dev/null || date -u -j -f "%Y-%m-%dT%H:%M:%S" "$LAST_RUN_CLEANED" +%s 2>/dev/null || echo "0")
          BEFORE_EPOCH=$(date -u -d "$BEFORE_JOB_CLEANED" +%s 2>/dev/null || date -u -j -f "%Y-%m-%dT%H:%M:%S" "$BEFORE_JOB_CLEANED" +%s 2>/dev/null || echo "0")
          
          echo "üî¢ Last run epoch: $LAST_RUN_EPOCH"
          echo "üî¢ Before epoch: $BEFORE_EPOCH"
          
          if [ "$LAST_RUN_EPOCH" = "0" ] || [ "$BEFORE_EPOCH" = "0" ]; then
            echo "‚ö†Ô∏è Date parsing failed, using simple string comparison"
            if [[ "$LAST_RUN" > "$BEFORE_JOB" ]] || [[ "$LAST_RUN" == "$BEFORE_JOB" ]]; then
              echo "‚úÖ Job 2 verified - timestamp is recent!"
              echo "verify_job2_status=success" >> $GITHUB_OUTPUT
            else
              echo "‚ùå Job 2 verification FAILED - timestamp is too old"
              echo "verify_job2_status=failed" >> $GITHUB_OUTPUT
              exit 1
            fi
          elif [ $LAST_RUN_EPOCH -gt $BEFORE_EPOCH ]; then
            echo "‚úÖ Job 2 verified - timestamp updated successfully!"
            echo "verify_job2_status=success" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Job 2 verification FAILED - timestamp not updated"
            echo "‚ùå Expected timestamp after: $BEFORE_JOB"
            echo "‚ùå Actual timestamp: $LAST_RUN"
            echo "verify_job2_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
      
      - name: Wait between jobs (5 seconds)
        run: |
          echo "‚è∏Ô∏è Waiting 5 seconds before next job..."
          sleep 5
      
      - name: Job 3 - Historical Price Snapshots
        id: job3
        continue-on-error: false
        run: |
          echo "üìà =========================================="
          echo "üìà JOB 3: Historical Price Snapshots"
          echo "üìà =========================================="
          echo "üìã What: Creates historical price snapshots"
          echo "üíæ Target: price_snapshots table"
          echo "‚è±Ô∏è Expected: 2-3 minutes"
          echo ""
          
          START_TIME=$(date +%s)
          echo "üïê Start time: $(date -u)"
          
          API_URL="https://mtg-bulk-jobs.onrender.com/price-snapshot"
          echo "üåê Calling: $API_URL"
          
          HTTP_CODE=$(curl -X POST \
            -H "x-cron-key: ${{ secrets.CRON_KEY }}" \
            -H "Content-Type: application/json" \
            -H "User-Agent: GitHub-Actions-Nightly-Import/1.0" \
            -w "%{http_code}" \
            -s \
            --max-time 600 \
            --connect-timeout 30 \
            "$API_URL" \
            -o response.json)
          
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo ""
          echo "‚è±Ô∏è Completed in: ${DURATION} seconds"
          echo "üì° HTTP Status: $HTTP_CODE"
          echo ""
          echo "üìÑ Response body:"
          cat response.json | jq '.' || cat response.json
          echo ""
          
          if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "202" ]; then
            echo "‚úÖ Job 3 completed successfully! (HTTP $HTTP_CODE)"
            
            if [ "$HTTP_CODE" = "202" ]; then
              echo "‚ÑπÔ∏è Job accepted and running in background (2-3 minutes)"
            fi
            
            INSERTED=$(cat response.json | jq -r '.inserted // "N/A"')
            SNAPSHOT_DATE=$(cat response.json | jq -r '.snapshot_date // "N/A"')
            echo "üìä Stats: Inserted=$INSERTED, Date=$SNAPSHOT_DATE"
          else
            echo "‚ùå Job 3 failed with HTTP $HTTP_CODE"
            echo "üîç Error details:"
            cat response.json | jq -r '.error // "No error message"' || echo "Could not parse error"
            exit 1
          fi
          
          echo "job3_duration=$DURATION" >> $GITHUB_OUTPUT
          echo "job3_status=success" >> $GITHUB_OUTPUT
      
      - name: Verify Job 3 Completion
        id: verify_job3
        continue-on-error: false
        run: |
          echo ""
          echo "üîç =========================================="
          echo "üîç VERIFYING JOB 3 COMPLETION"
          echo "üîç =========================================="
          echo ""
          echo "‚è≥ Waiting 6 minutes for background job to complete..."
          echo "‚è∞ Start wait: $(date -u)"
          sleep 360  # Wait 6 minutes for job to finish
          echo "‚è∞ End wait: $(date -u)"
          echo ""
          
          echo "üìä Checking database for completion..."
          
          # Query Supabase to check if job completed
          SUPABASE_URL="${{ secrets.SUPABASE_URL }}"
          SUPABASE_KEY="${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}"
          
          # Validate secrets are set
          if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_KEY" ]; then
            echo "‚ùå Missing Supabase secrets (SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY)"
            echo "verify_job3_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          # Get the timestamp before job started (approximately)
          BEFORE_JOB=$(date -u -d '10 minutes ago' +"%Y-%m-%dT%H:%M:%S" 2>/dev/null || date -u -v-10M +"%Y-%m-%dT%H:%M:%S" 2>/dev/null || echo "")
          
          if [ -z "$BEFORE_JOB" ]; then
            BEFORE_JOB=$(date -u +"%Y-%m-%dT%H:%M:%S")
            echo "‚ö†Ô∏è Could not calculate '10 minutes ago', using current time minus buffer"
          fi
          
          echo "üîç Querying: $SUPABASE_URL/rest/v1/app_config?key=eq.job:last:price_snapshot_bulk&select=value"
          
          # Check app_config for last run timestamp
          RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" \
            -H "apikey: $SUPABASE_KEY" \
            -H "Authorization: Bearer $SUPABASE_KEY" \
            "$SUPABASE_URL/rest/v1/app_config?key=eq.job:last:price_snapshot_bulk&select=value" || echo "")
          
          HTTP_CODE=$(echo "$RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2 || echo "000")
          RESPONSE_BODY=$(echo "$RESPONSE" | grep -v "HTTP_CODE:" || echo "")
          
          echo "üì° HTTP Status: $HTTP_CODE"
          echo "üìÑ Response: $RESPONSE_BODY"
          
          if [ "$HTTP_CODE" != "200" ]; then
            echo "‚ùå Supabase query failed with HTTP $HTTP_CODE"
            echo "verify_job3_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          LAST_RUN=$(echo "$RESPONSE_BODY" | jq -r '.[0].value // empty' 2>/dev/null || echo "")
          
          if [ -z "$LAST_RUN" ] || [ "$LAST_RUN" = "null" ]; then
            echo "‚ùå Could not find job:last:price_snapshot_bulk in database"
            echo "‚ùå Response was: $RESPONSE_BODY"
            echo "verify_job3_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "üìÖ Last run timestamp: $LAST_RUN"
          echo "üìÖ Job started after: $BEFORE_JOB"
          
          # Check if timestamp is recent (within last 15 minutes to account for job duration)
          LAST_RUN_CLEANED=$(echo "$LAST_RUN" | sed 's/\.[0-9]*//' | sed 's/Z$//')
          BEFORE_JOB_CLEANED=$(echo "$BEFORE_JOB" | sed 's/Z$//')
          
          LAST_RUN_EPOCH=$(date -u -d "$LAST_RUN_CLEANED" +%s 2>/dev/null || date -u -j -f "%Y-%m-%dT%H:%M:%S" "$LAST_RUN_CLEANED" +%s 2>/dev/null || echo "0")
          BEFORE_EPOCH=$(date -u -d "$BEFORE_JOB_CLEANED" +%s 2>/dev/null || date -u -j -f "%Y-%m-%dT%H:%M:%S" "$BEFORE_JOB_CLEANED" +%s 2>/dev/null || echo "0")
          
          echo "üî¢ Last run epoch: $LAST_RUN_EPOCH"
          echo "üî¢ Before epoch: $BEFORE_EPOCH"
          
          if [ "$LAST_RUN_EPOCH" = "0" ] || [ "$BEFORE_EPOCH" = "0" ]; then
            echo "‚ö†Ô∏è Date parsing failed, using simple string comparison"
            if [[ "$LAST_RUN" > "$BEFORE_JOB" ]] || [[ "$LAST_RUN" == "$BEFORE_JOB" ]]; then
              echo "‚úÖ Job 3 verified - timestamp is recent!"
              echo "verify_job3_status=success" >> $GITHUB_OUTPUT
            else
              echo "‚ùå Job 3 verification FAILED - timestamp is too old"
              echo "verify_job3_status=failed" >> $GITHUB_OUTPUT
              exit 1
            fi
          elif [ $LAST_RUN_EPOCH -gt $BEFORE_EPOCH ]; then
            echo "‚úÖ Job 3 verified - timestamp updated successfully!"
            echo "verify_job3_status=success" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Job 3 verification FAILED - timestamp not updated"
            echo "‚ùå Expected timestamp after: $BEFORE_JOB"
            echo "‚ùå Actual timestamp: $LAST_RUN"
            echo "verify_job3_status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi
      
      - name: Send Email on Failure
        if: failure()
        uses: dawidd6/action-send-mail@v3
        continue-on-error: true
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "‚ùå MTG AI Assistant - Nightly Jobs FAILED"
          to: ${{ secrets.ADMIN_EMAIL }}
          from: "MTG AI Assistant <${{ secrets.EMAIL_USERNAME }}>"
          body: |
            üö® NIGHTLY BULK DATA IMPORT FAILED üö®
            
            Run Date: ${{ github.event.repository.updated_at }}
            Workflow Run: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
            
            Job Results:
            - Job 2 (Price Import): ${{ steps.job2.outputs.job2_status || 'FAILED' }}
            - Job 2 Verification: ${{ steps.verify_job2.outputs.verify_job2_status || 'FAILED' }}
            - Job 3 (Price Snapshots): ${{ steps.job3.outputs.job3_status || 'FAILED' }}
            - Job 3 Verification: ${{ steps.verify_job3.outputs.verify_job3_status || 'FAILED' }}
            
            Please check the logs at the workflow link above.
            
            --- 
            Automated message from GitHub Actions
      
      - name: Summary
        if: always()
        run: |
          echo ""
          echo "üéâ =========================================="
          echo "üéâ NIGHTLY IMPORT SUMMARY"
          echo "üéâ =========================================="
          echo ""
          echo "üìÖ Run completed: $(date -u)"
          echo ""
          echo "Job Results:"
          echo "  üé® Job 1 (Metadata):  ${{ steps.job1.outputs.job1_status || 'DISABLED' }} - ${{ steps.job1.outputs.job1_duration || 'N/A' }}s"
          echo "  üí∞ Job 2 (Prices):    ${{ steps.job2.outputs.job2_status || 'FAILED' }} - ${{ steps.job2.outputs.job2_duration || 'N/A' }}s"
          echo "  üîç Job 2 Verification: ${{ steps.verify_job2.outputs.verify_job2_status || 'FAILED' }}"
          echo "  üìà Job 3 (Snapshots): ${{ steps.job3.outputs.job3_status || 'FAILED' }} - ${{ steps.job3.outputs.job3_duration || 'N/A' }}s"
          echo "  üîç Job 3 Verification: ${{ steps.verify_job3.outputs.verify_job3_status || 'FAILED' }}"
          echo ""
          
          TOTAL_TIME=$((
            ${{ steps.job1.outputs.job1_duration || 0 }} +
            ${{ steps.job2.outputs.job2_duration || 0 }} +
            ${{ steps.job3.outputs.job3_duration || 0 }}
          ))
          echo "‚è±Ô∏è Total runtime: ${TOTAL_TIME} seconds (~$((TOTAL_TIME / 60)) minutes)"
          echo ""
          
          if [ "${{ job.status }}" = "success" ]; then
            echo "‚úÖ All jobs completed successfully!"
          else
            echo "‚ùå Some jobs failed - check logs above"
          fi
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: failure-logs-${{ github.run_id }}
          path: |
            response.json
          retention-days: 7

